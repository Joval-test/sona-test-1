{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=AzureOpenAIEmbeddings(\n",
    "        azure_endpoint=\"https://ai-gpu-ps.openai.azure.com/\",\n",
    "        azure_deployment=\"gpt40-mini-long-context\",\n",
    "        openai_api_version=\"2024-05-01-preview\",\n",
    "        api_key=\"dc415207c54e4dd8ba8b60cb66374822\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_collection = Chroma(\n",
    "        collection_name=\"company_info_store\",\n",
    "        persist_directory=\"chroma_storage\",\n",
    "        embedding_function=embeddings,\n",
    "        collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash ID 'fa510296a7d556be18bf44d452698dc12c44e06edd0de9d3d5a2f81a5ca811f9' does not exist in the collection.\n"
     ]
    }
   ],
   "source": [
    "hash_id = \"fa510296a7d556be18bf44d452698dc12c44e06edd0de9d3d5a2f81a5ca811f9\"\n",
    "\n",
    "all_ids = company_collection.get()[\"ids\"]\n",
    "if hash_id in all_ids:\n",
    "    print(f\"Hash ID '{hash_id}' exists in the collection.\")\n",
    "else:\n",
    "    print(f\"Hash ID '{hash_id}' does not exist in the collection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_docs = company_collection.get(where={\"content_hash\": content_hash})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.1\",base_url=\"3.110.55.125:11434\")\n",
    "response=llm.invoke(\"hai who is this?\")\n",
    "print(response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cold_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
